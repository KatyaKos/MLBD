{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Student-Model\" data-toc-modified-id=\"Student-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Student Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-processing\" data-toc-modified-id=\"Data-processing-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data processing</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Model\" data-toc-modified-id=\"Define-Model-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Define Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#ROC-AUC\" data-toc-modified-id=\"ROC-AUC-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>ROC AUC</a></span></li><li><span><a href=\"#Compression-rate\" data-toc-modified-id=\"Compression-rate-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Compression rate</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Model\n",
    "\n",
    "\n",
    "Нужно обучть небольшую модель на [soft таргетах](https://drive.google.com/file/d/1tBbPOUT-Ow9f3zTDApykGXYwt-KslYle/view?usp=sharing)  модели учителя, которая не сильно уступала бы в качестве учителю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr/#history\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr.models.dcn import DCN\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "SOFT_PATH = 'soft_targets_full.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Данные на Train/Validation/Test нужно разбить как 80/10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_features_indices = [i for i in range(1, 14)]\n",
    "sparse_features_indices = [i for i in range(14, 40)]\n",
    "\n",
    "dense_features = ['c{}'.format(i) for i in dense_features_indices]\n",
    "sparse_features = ['c{}'.format(i) for i in sparse_features_indices]\n",
    "\n",
    "len(dense_features_indices), len(sparse_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.5/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(TRAIN_PATH, index_col='id')\n",
    "data.rename(columns=dict([(col, col[1:] if col[0] == '_' else col) for col in data.columns]), inplace=True)\n",
    "soft_data = pd.read_csv(SOFT_PATH, index_col='id')\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "data['soft_c0'] = soft_data\n",
    "targets = ['c0', 'soft_c0']\n",
    "soft_target = 'soft_c0'\n",
    "hard_target = 'c0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931944\n",
      "366493\n",
      "366494\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, shuffle=False)\n",
    "val, test = train_test_split(test, test_size=0.5, shuffle=False)\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features_dims = dict([\n",
    "    ('c14', 1445),\n",
    "    ('c15', 556),\n",
    "    ('c16', 1130758),\n",
    "    ('c17', 360209),\n",
    "    ('c18', 304),\n",
    "    ('c19', 21),\n",
    "    ('c20', 11845),\n",
    "    ('c21', 631),\n",
    "    ('c22', 3),\n",
    "    ('c23', 49223),\n",
    "    ('c24', 5194),\n",
    "    ('c25', 985420),\n",
    "    ('c26', 3157),\n",
    "    ('c27', 26),\n",
    "    ('c28', 11588),\n",
    "    ('c29', 715441),\n",
    "    ('c30', 10),\n",
    "    ('c31', 4681),\n",
    "    ('c32', 2029),\n",
    "    ('c33', 4),\n",
    "    ('c34', 870796),\n",
    "    ('c35', 17),\n",
    "    ('c36', 15),\n",
    "    ('c37', 87605),\n",
    "    ('c38', 84),\n",
    "    ('c39', 58187)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input(df):\n",
    "    feature_names = dense_features + sparse_features\n",
    "    return {name: (pd.core.series.Series(df[name]) if name in sparse_features else np.array(df[name]))\n",
    "            for name in feature_names}\n",
    "\n",
    "train_input = gen_model_input(train)\n",
    "val_input = gen_model_input(val)\n",
    "test_input = gen_model_input(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Можно также использовать Pruning и/или Quantinization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def hyb_loss(q, g):\n",
    "    w = 0.9\n",
    "    l1 = tf.keras.backend.binary_crossentropy(tf.gather(q, [1], axis=1), tf.gather(g, [1], axis=1),\n",
    "                                              from_logits=False)\n",
    "    l2 = tf.keras.backend.binary_crossentropy(tf.gather(q, [1], axis=1), tf.gather(g, [0], axis=1),\n",
    "                                              from_logits=False)\n",
    "    return w * l1 + (1 - w) * l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_dcn_model(mode='mse', max_voc_size=50000, max_emb_dim=100, dnn_hidden=(128, 128)):\n",
    "    fixlen_feature_columns = [SparseFeat(feat, \n",
    "                                     vocabulary_size=min(vocab_size, max_voc_size),\n",
    "                                     embedding_dim=min(int(6 * (vocab_size) ** (0.25)), max_emb_dim), \n",
    "                                     use_hash=True, dtype='string') \n",
    "                          for feat, vocab_size in sparse_features_dims.items()] + \\\n",
    "                        [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "    model = DCN(fixlen_feature_columns, fixlen_feature_columns, cross_num=2,\n",
    "            dnn_hidden_units=dnn_hidden, l2_reg_linear=0, l2_reg_embedding=0,\n",
    "            l2_reg_cross=0, l2_reg_dnn=0, init_std=0.0001, seed=1024, \n",
    "            dnn_use_bn=True, dnn_activation='relu', task='binary')\n",
    "    \n",
    "    if mode == \"mse\":\n",
    "        model.compile(\"adam\", tf.keras.losses.MeanSquaredError(), )\n",
    "        \n",
    "        model.fit(train_input, train[soft_target].values,\n",
    "                  batch_size=BATCH, use_multiprocessing=True,\n",
    "                  validation_data = (val_input, val[soft_target].values))\n",
    "    elif mode == \"hyb\":\n",
    "        model.compile(\"adam\", hyb_loss, )\n",
    "        \n",
    "        model.fit(train_input, train[targets].values,\n",
    "                  batch_size=BATCH, use_multiprocessing=True,\n",
    "                  validation_data = (val_input, val[targets].values))\n",
    "    else:\n",
    "        print(\"No such mode\")\n",
    "        return None\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 589s 201us/sample - loss: 0.0044 - val_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "mse_hid32_model = make_dcn_model('mse', dnn_hidden=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 152s 52us/sample - loss: 0.0043 - val_loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "mse_emb16_model = make_dcn_model('mse', max_emb_dim=16, max_voc_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 231s 79us/sample - loss: 0.0038 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "mse_emb32_model = make_dcn_model('mse', max_emb_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 230s 78us/sample - loss: 0.0054 - val_loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "mse_hid32_voc10k_model = make_dcn_model('mse', dnn_hidden=(32, 32), max_voc_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyb_hid32_model = make_dcn_model('hyb', dnn_hidden=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyb_emb32_model = make_dcn_model('mse', max_emb_dim=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Наша основная задача получить модель, которая \n",
    "* в терминах ROC AUC не намного хуже модели учителя, и в то же время \n",
    "* сильно меньше по размеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC\n",
    "\n",
    "Сравним ROC AUC модели ученика с показателем для учителя.\n",
    "\n",
    "ROC AUC учителя: 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "TEACHER_SIZE = 168\n",
    "TEACHER_AUC = 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_hid32_ans = mse_hid32_model.predict(test_input, batch_size=BATCH)\n",
    "tf.keras.models.save_model(mse_hid32_model, \"tmp.h5\", include_optimizer=False)\n",
    "results['mse_hid32'] = {'auc': roc_auc_score(test[hard_target].values, mse_hid32_ans),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_emb32_ans = mse_emb32_model.predict(test_input, batch_size=BATCH)\n",
    "tf.keras.models.save_model(mse_emb32_model, \"tmp.h5\", include_optimizer=False)\n",
    "results['mse_emb32'] = {'auc': round(roc_auc_score(test[hard_target].values, mse_emb32_ans), 4),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_emb16_ans = mse_emb16_model.predict(test_input, batch_size=BATCH)\n",
    "mse_emb16_model.save_weights(\"tmp.h5\")\n",
    "results['mse_emb16'] = {'auc': round(roc_auc_score(test[hard_target].values, mse_emb16_ans), 4),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_hid32_voc10k_ans = mse_hid32_voc10k_model.predict(test_input, batch_size=BATCH)\n",
    "mse_hid32_voc10k_model.save_weights(\"tmp.h5\")\n",
    "results['mse_hid32_voc10k'] = {'auc': round(roc_auc_score(test[hard_target].values, mse_hid32_voc10k_ans), 4),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results:\n",
    "    tmp = results[key]\n",
    "    tmp['auc_rate']=round(tmp['auc'] / TEACHER_AUC, 4)\n",
    "    results[key] = {'auc_rate': round(tmp['auc'] / TEACHER_AUC, 4), 'comprassion_rate': tmp['comprassion_rate']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression rate\n",
    "\n",
    "Пусть \n",
    "* $a$ - \\# of the parameters in the original model $M$\n",
    "* $a^{*}$ - \\# of the parameters in compressed model $M^{*}$\n",
    "\n",
    "тогда compression rate is $$\\alpha(M,M^{*}) = \\frac{a}{a^{*}}$$\n",
    "\n",
    "Можно также посчитать comression rate просто как отношение фактических размеров моделей.\n",
    "\n",
    "Размер модели учителя - 168MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse_emb16': {'auc_rate': 0.9814, 'comprassion_rate': 8.9473},\n",
       " 'mse_emb32': {'auc_rate': 0.9852, 'comprassion_rate': 2.9907},\n",
       " 'mse_hid32': {'auc_rate': 0.9836, 'comprassion_rate': 1.0521},\n",
       " 'mse_hid32_voc10k': {'auc_rate': 0.9778, 'comprassion_rate': 4.3605}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "\n",
    "[link](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization\n",
    "from tensorflow_model_optimization.python.core.api.sparsity import keras as sparsity\n",
    "\n",
    "end_step = np.ceil(1.0 * len(train) / BATCH).astype(np.int32) * 10\n",
    "\n",
    "def make_pruned_model(max_voc_size=50000, max_emb_dim=100, dnn_hidden=(128, 128), steps=3):\n",
    "    fixlen_feature_columns = [SparseFeat(feat, \n",
    "                                     vocabulary_size=min(vocab_size, max_voc_size),\n",
    "                                     embedding_dim=min(int(6 * (vocab_size) ** (0.25)), max_emb_dim), \n",
    "                                     use_hash=True, dtype='string') \n",
    "                          for feat, vocab_size in sparse_features_dims.items()] + \\\n",
    "                        [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "    model = DCN(fixlen_feature_columns, fixlen_feature_columns, cross_num=2,\n",
    "            dnn_hidden_units=dnn_hidden, l2_reg_linear=0, l2_reg_embedding=0,\n",
    "            l2_reg_cross=0, l2_reg_dnn=0, init_std=0.0001, seed=1024, \n",
    "            dnn_use_bn=True, dnn_activation='relu', task='binary')\n",
    "    model.compile(\"adam\", tf.keras.losses.MeanSquaredError(), )\n",
    "    \n",
    "    for i in range(steps):\n",
    "        print(\"Step\", i)\n",
    "        pruning_params = {\n",
    "              'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=2000,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "        }\n",
    "        model = sparsity.prune_low_magnitude(model, **pruning_params)\n",
    "        model.compile(\"adam\", tf.keras.losses.MeanSquaredError(), )\n",
    "        callbacks = [sparsity.UpdatePruningStep()]\n",
    "        model.fit(train_input, train[soft_target].values,\n",
    "                  batch_size=BATCH, use_multiprocessing=True,\n",
    "                  validation_data = (val_input, val[soft_target].values),\n",
    "                  callbacks = callbacks)\n",
    "        \n",
    "        model = sparsity.strip_pruning(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "WARNING:tensorflow:From /workspace/MLBD/dnn_compression_acceleration/notebooks/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:225: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 461s 157us/sample - loss: 0.0042 - val_loss: 0.0025\n",
      "Step 1\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 455s 155us/sample - loss: 0.0019 - val_loss: 0.0020\n",
      "Step 2\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 460s 157us/sample - loss: 0.0012 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "mse_emb32_pruned_model = make_pruned_model(max_voc_size=30000, max_emb_dim=32, dnn_hidden=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 763s 260us/sample - loss: 0.0051 - val_loss: 0.0028\n",
      "Step 1\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 737s 251us/sample - loss: 0.0021 - val_loss: 0.0024\n",
      "Step 2\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 738s 252us/sample - loss: 0.0014 - val_loss: 0.0022\n",
      "Step 3\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 706s 241us/sample - loss: 0.0011 - val_loss: 0.0020\n",
      "Step 4\n",
      "Train on 2931944 samples, validate on 366493 samples\n",
      "2931944/2931944 [==============================] - 746s 254us/sample - loss: 8.5979e-04 - val_loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "mse_hid32_pruned_model = make_pruned_model(max_voc_size=30000, max_emb_dim=100, dnn_hidden=(32, 32), steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "TEACHER_SIZE = 168\n",
    "TEACHER_AUC = 0.802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_emb32_pruned_ans = mse_emb32_pruned_model.predict(test_input, batch_size=BATCH)\n",
    "tf.keras.models.save_model(mse_emb32_pruned_model, \"tmp.h5\", include_optimizer=False)\n",
    "results['mse_emb32_pruned'] = {'auc': roc_auc_score(test[hard_target].values, mse_emb32_pruned_ans),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_hid32_pruned_ans = mse_hid32_pruned_model.predict(test_input, batch_size=BATCH)\n",
    "tf.keras.models.save_model(mse_hid32_pruned_model, \"tmp.h5\", include_optimizer=False)\n",
    "results['mse_hid32_pruned'] = {'auc': roc_auc_score(test[hard_target].values, mse_hid32_pruned_ans),\n",
    "                        'comprassion_rate': round(TEACHER_SIZE / (os.path.getsize(\"tmp.h5\") / float(2**20)), 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results:\n",
    "    tmp = results[key]\n",
    "    tmp['auc'] = round(tmp['auc'], 4)\n",
    "    tmp['auc_rate']=round(tmp['auc'] / TEACHER_AUC, 4)\n",
    "    results[key] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse_emb32_pruned': {'auc': 0.7908,\n",
       "  'auc_rate': 0.986,\n",
       "  'comprassion_rate': 59.6502},\n",
       " 'mse_hid32_pruned': {'auc': 0.7893,\n",
       "  'auc_rate': 0.9842,\n",
       "  'comprassion_rate': 41.6854}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
